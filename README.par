	  Alternative WWWOFFLE implementation - version 2.8e-par-9
                             by Paul Rombouts
	  ========================================================

This file describes the customized version of WWWOFFLE that I use personally and
am making available so other people can run it and/or study the source code.
Present version is 2.8e-par-9 (I've simply appended my initials to the version
number). Versions 2.8e-par and later introduce an important efficiency
improvement: the number of files in the spool directory are reduced by nearly
50% by using a single compact database file to remember the URLs belonging to
the cached webpages.

The first part of this file describes how to patch, compile, install and run
wwwoffled. Please note that if you wish to use an existing WWWOFFLE spool
directory the files in the cache (those beginning with 'U') must be converted
into a database file before you can start wwwoffled. The second part lists in
more detail the changes I've made to AMB's code.

Before compiling and installing WWWOFFLE according to AMB's installation
instructions described in the INSTALL file you must first apply my patch file
wwwoffled-2.8e-par-9.diff.gz. Use a freshly untarred copy of Andrew Bishop's
original version 2.8e source, cd into the source directory wwwoffle-2.8e and
apply the command:

gzip -cd <path_to_patch>/wwwoffle-2.8e-par-9.diff.gz | patch -p2 -N -E

Note: because I have used GNU extensions you will need to compile with gcc and
link with glibc. This will not be a problem with most Linux distributions.
If you get some weird error messages about "Malformed UTF-8 characters" from the
perl interpreter (this happened to me after I upgraded to Red Hat 9) try again
after running the command (assuming you use a bash shell):

  export LANG=${LANG%%.*}

If you want to use an existing WWWOFFLE configuration file then you must make
the following change to the configuration file before you can run wwwoffled:
split section CensorHeader into two sections called CensorIncomingHeader and
CensorOutgoingHeader. These sections should contain only options that apply to
the censoring of reply headers coming back from servers and request headers sent
to servers, respectively. The referer-self(-dir) options go into the
CensorOutgoingHeader section.  Alternatively, if you're not using the
CensorHeader section at all it is easier to simply delete it in its entirety.

Important: If you want to use an existing WWWOFFLE spool directory you must
convert the information in the U* files in the cache to a new database file
called "urlhashtable". You need to execute the following steps as root:
- First it is recommended that you make a backup copy of your spool directory
  (don't worry, the conversion is reversible, this is just a precaution).
- Change to the wwwoffle-2.8e/src directory and run "./make_urlhash_file" .
- The U* files are no longer needed and just waste disk space. You can run the
  script "rm_Ufiles.sh" to remove them immediately; otherwise they will
  removed the next time you run "wwwoffle -purge".

That's it! You should now be able to run wwwoffled and enjoy the improved
performance. You should be able to notice that WWWOFFLE accesses the hard disk
less often and that especially the cache index pages are generated much
faster. To give you an idea of the speedup: on my system the time to do a
complete "wwwoffle -purge" with "use-url = yes" has been reduced by a factor
of 4.

Note: should you want to go back to using AMB's original version, you will have
to restore the U* files first by running the "restore_Ufiles" utility in the
wwwoffle-2.8e/src directory.

Note: my patch unfortunately breaks the functionality of the wwwoffle-tools
(wwwoffle-hash wwwoffle-ls wwwoffle-mv wwwoffle-read wwwoffle-rm
wwwoffle-write). Since I do not use them myself, I have no immediate plans for
fixing them. However, if I receive enough requests, I will reconsider.

Note to users of languages besides English: I've modified some of the WWWOFFLE
message templates for the English. If you want to use a different language you
will have to look at the modifications in the templates that have been patched
and apply these changes to the template files of your own language.
Alternatively you could simply delete the non-English template files so that the
English language versions are used instead. wwwoffled will still run without
these changes, but then some of the configuration pages will not display
correctly.


I've introduced a few extensions to the way WWWOFFLE can be configured:

- New in version 2.8e-par-9: I have added a new option to the OnlineOptions
  section called keep-cache-if-header-matches. This option is similar to
  keep-cache-if-not-found, but examines the header lines (instead of the status
  code) of the reply from the remote server to determine whether the previously
  cached version should be kept, rather than be overwritten by the new page. The
  keep-cache-if-header-matches option can be set to a pattern string. If one of
  the header lines of the reply matches the pattern and there is a "good" cached
  version of the page, the cached version is kept.

- New in version 2.8e-par-6: There are two new options for the ModifyHTML
  section: insert-file and disable-dontget-script. The insert-file option can be
  used to add the content of a local file at the end of a webpage, without
  modifications. One of the more powerful applications of this feature is to add
  your own Javascript to webpages; this allows you to implement most of the
  possibilities of Greasemonkey, a popular Firefox extension, even on browsers
  that do not support Greasemonkey (but do support Javascript).
  The disable-dontget-script option works like the disable-script option, but
  only disables external scripts with a src attribute that matches the DontGet
  list. Often the WWWOFFLE replacement of a DontGet URL is not valid Javascript,
  which can cause distracting error messages in the browser. This can be
  prevented by enabling disable-dontget-script.

- New in version 2.8e-par-4: I have added support for the SOCKS 4A protocol.
  By default, when connecting through a SOCKS proxy server the destination host
  name is resolved locally and the IP address is given to the SOCKS server.
  Sometimes this is not what you want. By setting the new socks-remote-dns
  option to yes, WWWOFFLE will not attempt to resolve the name and will supply
  the host name directly to the SOCKS server.

- New in version 2.8d-3: I've added a new option to the ModifyHTML section
  called replacement-meta-refresh-time. If this is set to a non-negative value,
  the delay time in the meta refresh tag will replaced with this value.
  The default is -1, which means the meta tag will be removed as in the standard
  version of WWWOFFLE.
  I find this option useful to avoid certain interstitial ads, which use a meta
  refresh tag to automatically direct the browser to the page with the actual
  content after a certain delay. I use this option to set the delay time to 0,
  which means I get to see the page I am actually interested in without any
  delay.

- New in version 2.8d: I've added support for connecting via SOCKS 4 proxies.
  I personally use this feature with OpenSSH as the SOCKS server.
  For example, you can start ssh as a SOCKS server with the command

	ssh -NTx -D 1080 remotehost

  and configure wwwoffled by adding the following line to the "Proxy" section in
  the config file:

	<*://*.protecteddomain> socks = localhost:1080

  Now if you use WWWOFFLE to browse www.protecteddomain, to the web server the
  connection will appear to originate from remotehost. This can be very useful
  if www.protecteddomain is behind a firewall and cannot be reached directly,
  or if www.protecteddomain will only allow full access to clients within a
  certain range of IP addresses.
  Note: this feature currently only works for IPv4.

- New in version 2.7h: I've included a patch provided by Marc Boucher
  <MarcB@box100.com>. This implements a new configuration option called
  always-use-etag. The so called entity tag can be used to validate the contents
  of the cache with the remote server without having having to download the
  content of a webpage if it has not changed. Unfortunately many servers (or
  rather server farms) will issue different entity tags for identical content,
  defeating the usefulness of conditional requests with entity tags because
  WWWOFFLE will end up downloading the same content needlessly. Setting the
  option always-use-etag = no in the OnlineOptions section will configure
  WWWOFFLE to send conditional requests based on the Last-Modified time only,
  unless the Last-Modified time cannot be considered a strong validator (based
  on a heuristic criterion).
  Note: in version 2.8d this option is now called validate-with-etag,
  but I still use Marc Boucher's implementation of this option.

- I've added a new option to the OnlineOptions section called
  keep-cache-if-not-found. When this option is enabled for a certain URL, then
  if WWWOFFLE online and the remote server returns a status code >=300, and
  there is a previously cached version for this URL with status code 200,
  WWWOFFLE will write a warning message to the cache and keep the previously
  cached page as a backup. This is useful for preventing old cached versions of
  pages being overwritten by error messages from a web server.

- I've added an option to the CensorIncomingHeader section called
  session-cookies-only. When enabled, WWWOFFLE strips the "expires" field from
  "Set-Cookie:" server headers. Most browsers will not store such cookies
  permanently and forget them in between sessions. I find this significantly
  reduces the number of permanently stored cookies, while preserving most of the
  functionality of sites that require you to accept cookies. You can use a
  URL-specification to make exceptions for sites whose cookies you want to keep.
  The syntax for this option is [<URL-SPEC>] session-cookies-only = yes | no.
  Note: in version 2.7h-par-2 the "expires" field is only stripped if it refers
  to a time in the future. Expire times in the past should cause browsers to
  delete cookies and I don't want to prevent that.

- I've added an option to the OfflineOptions section called
  "cache-control-no-cache" that is very similar to "pragma-no-cache", except
  that it effects the way WWWOFFLE treats "Cache-Control: no-cache" and
  "Cache-Control: max-age=0" instead of "Pragma: no-cache" header lines. When
  you hit the reload button on your browser while WWWOFFLE is offline this can
  cause a number of outgoing requests to be generated. My experience is that
  this often includes a large number of requests for small gif images that are
  really unnecessary. This option can be used to reduce the number these
  requests. The syntax is [<URL-SPEC>] cache-control-no-cache = yes | no.

- I've allowed URL-specifications to contain an equals-sign. This allows you to
  include something like "http://*.com/images/*?*sz=120x480*" in the DontGet
  section of the configuration file. Originally it was impossible to use a
  URL-specification like that (replacing '=' by '%3D' won't work).

- URL specifications are allowed to have a so-called parameters part. This
  allows you to use something like "http://*.com/images*;*sz=120x480*". In the
  original version of WWWOFFLE a URL specification containing a ';' in the path
  part will never match.

- I've expanded the set of values the option request-compression is allowed to
  take to include "gzip" and "deflate". This allows you to fine-tune the type of
  compression WWWOFFLE asks for in case there are problems with a particular
  method of compression.


The rest of this file lists in some detail some other modifications I've made,
but you don't have to read it if you simply want to run wwwoffled as you're used
to.

- In version 2.8e-par-9 some of the HTML parsing rules have been fixed (in
  src/html.l and src/htmlmodify.l), which improves the ability of WWWOFFLE to
  parse java-scripts.

- In version 2.8e-par-8 a memory leak has been fixed which makes the WWWOFFLE
  server vulnerable to a denial-of-service attack via the wwwoffle control port
  (leak is also present in the original WWWOFFLE). Also a double-free bug has
  been fixed which may cause a WWWOFFLE child process to crash (only present in
  my version of WWWOFFLE).

- In version 2.8e-par-7 when disable-script=yes scripts are commented out in
  HTML documents instead of removed. This enables you to still see javascript
  code when viewing the HTML source in a browser. This is useful for debugging
  purposes. The text of disabled scripts is also accessible by scripts that you
  add yourself (via greasemonkey or the new insert-file option).
  I have included a fix for a compilation issue that can occur with newer flex
  versions.

- In version 2.8e-par-6 I have addressed an issue with double dashes "--" inside
  HTML comments (see http://www.howtocreate.co.uk/SGMLComments.html). This used
  to effect WWWOFFLE message pages and HTML pages modified by WWWOFFLE in
  combination with certain browsers.
  The replacement-dontget-image option can now be set to none with the expected
  effect. In the original version of WWWOFFLE this setting would cause WWWOFFLE
  to crash.
  I have fixed a problem with a stack in the function modify_html() that could
  overflow and/or misalign.

- In version 2.8e-par-5 I have extended the SOCKS support to include the finger
  protocol. Also fixed a bug that caused a WWWOFFLE child process to abort
  ungracefully if a connection to a finger host fails.

- New in version 2.8e-par-2: The make_urlhash_file and restore_Ufiles utilities
  can now be restricted to act on selected subdirectories instead of the whole
  cache.

- I have fixed a bug caused by a race condition where a WWWOFFLE process
  sometimes fails to detect that a new host directory has already been created
  and produces confusing error messages.

- Do not store WWWOFFLE messages in the cache in chunked format.

- New in version 2.8e: The URLs of the cached webpages are stored in a single
  compact database file called "urlhashtable" instead of the many small U*
  files. This reduces the number of files in the WWWOFFLE cache by almost
  50%. Having many small files is quite inefficient. For example, on my system
  each U* file occupies 4K of disk space. With 78587 U* files that is 307MB of
  occupied disk space. My "urlhashtable" file uses less than 7MB! If you run
   "ls -l /var/spool/wwwoffle" the file "urlhashtable" may appear to be quite
  large, but in fact it is a so-called sparse file. The real size of the file
  (in bytes) can be found by running the command
   "od -t u4 -N 4 /var/spool/wwwoffle/urlhashtable".
  To find out how much disk space it actually occupies, use the "du" utility.
  New entries are appended to the end of the url-hash file, so the file will
  keep growing until it is compacted at the end of a WWWOFFLE purge. During this
  compaction WWWOFFLE may be unresponsive for a few seconds.

- New in version 2.8d: AMB's version of the code never includes a Context-Length
  header line in replies to clients. I choose to use a Context-Length header
  when the size of the page is known in advance. This also eliminates the need
  for using chunked encoding and the (slight) overhead caused by this in a
  number of cases.

- New in version 2.8d: The original version of wwwoffled misses a number of
  opportunities to reply with "304 Not Modified" to conditional requests but
  serves the complete contents of a spooled page instead. I believe I have now
  fixed this.

- New in version 2.8d: There is a logical error in AMB's implementation of
  io_chunk_encode(). I don't know if this will ever be a problem in practice,
  but I believe my version is more correct.

- New in version 2.7h-par-2: I've made the wwwoffle control executable smaller
  by eliminating a lot of unnecessary code.

- New in version 2.7h-par-2: More consistent timeout behavior. In the original
  WWWOFFLE version, when a connection is established with a remote server, but
  the server takes forever to send a reply header, wwwoffled sometimes would
  take a very long time to timeout. I think I have now fixed this problem.
  Thanks to Marc Boucher for pointing out the cause of this problem in the
  source code.

- New in version 2.7h-par-2: An environment variable ONLINE is passed on to
  CGI-scripts. This has the value 1 if WWWOFFLE is online, 0 if offline, and -1
  in autodial mode.

- I've added a new option to the cache index pages that enables you to see the
  titles of the listed webpages (those that WWWOFFLE can find in the cache). I
  find it useful because it generally gives you a better idea what the pages are
  about. Note: this feature requires modified message template files and they
  are not available in all languages. The quickest way to remedy this problem is
  to revert to English only by removing all non-english directories in
  /var/spool/wwwoffle/html. To see if this feature is available look at the top
  of an index page for a (Show Titles) option.
  Note: in version 2.7h-par-2 the parsing of titles has been improved.

- I've fixed a bug (at least I consider it a bug) that caused all references to
  a webpage to disappear from the lasttime indexes whenever a webserver replies
  with 304 (Not Modified). My version of the code will not add a new entry to
  the lasttime directory in this case, but it will not remove existing ones
  either.

- I've made a few changes to improve WWWOFFLE's ability to block sites that
  (ab)use the SSL protocol (i.e. the URL starts with https) for ads. If WWWOFFLE
  refuses a SSL-proxy connect because the host appears on the DontGet list,
  WWWOFFLE will now give a more sensible error message instead of the confusing
  'SSL port not allowed' message. I've also changed the wwwoffle.pac file so
  that the SSL connections that I want to block go through WWWOFFLE (I normally
  don't use WWWOFFLE as a SSL-proxy).

- I've optimized the way the hash values that are used to construct the spool
  file names are computed. In stead of re-computing the hash value every time it
  is needed, a copy is stored in the URL struct the first it is computed. This
  cached value is used whenever the hash is needed again for the same URL.

- I've changed the way HTTP headers are parsed and manipulated back to the way
  it was done in version 2.6 of WWWOFFLE. In version 2.7 header lines with the
  same "key" are combined using a ',' as separator. While AMB correctly argues
  that the RFCs explicitly allow this, I see it as unnecessary and undesirable.
  I prefer a proxy to be as conservative as possible with headers, and I think
  the problems that have occurred with "Set-Cookie:" header-lines prove my
  point. I didn't simply reintroduce the version 2.6d code, but made sure to
  match the semantics of version 2.7 as closely as possible.

- I've eliminated the size field of the Header struct. Header sizes are now
  computed using ParseReply() and HeaderString(). This method is much less
  error-prone because it eliminates the need for re-adjusting the size field
  each time something is changed in a header. It also makes it possible to get
  the correct size of headers that use a different syntax than usual,
  e.g. header lines returned from CGI-scripts may end in LF instead of CR-LF.

- My handling of CGI-scripts more closely adheres to the CGI-specification
  described at http://hoohoo.ncsa.uiuc.edu/cgi/interface.html. If the argument
  of a "Location:" directive is not a URL but a virtual path, the server will
  retrieve the document specified as if the client had requested that document
  originally. (Infinite recursion within the wwwoffle server is prevented by
  using a counter.) If the output of a local CGI-script begins with a valid HTTP
  status-line it is passed on unmodified to the client instead of being ignored
  as in AMB's code. Furthermore, my handling of CGI-scripts is more efficient
  because it minimizes the use of temporary files and pipes.

- I've eliminated most calls of strcat() in favor of stpcpy() and memcpy(),
  which are more efficient. (I'm talking quadratic versus linear time-complexity
  here.) Why the use of strcat() is usually a bad idea is also explained in the
  glibc info pages.

- In some functions in src/miscencdec.c I've introduced some code to compute the
  exact size of the result that has to be dynamically allocated. This avoids
  wasting space on the heap and/or eliminates the need for calling realloc().

- I've changed the buffered I/O routines in src/io.c to make reading from a
  buffer independent of the (fdbuf) buffer size. In AMB's code, every time a small
  amount of data is read from a buffer, memmove() is used to shift the remaining
  data in the buffer. This makes the use of a larger buffer less instead of more
  efficient. Furthermore I've fixed a bug that sometimes causes compressed pages
  to be incompletely decompressed.

- I found the use of the functions SplitHostPort() and RejoinHostPort() ugly and
  inefficient. By introducing three extra fields to the URL struct (called
  hostport, port and portnum) I could eliminate most the most frequently used
  invocations of SplitHostPort() and RejoinHostPort(). For the remaining places
  where SplitHostPort() is used, I wrote a version of SplitHostPort() without
  side effects, thus eliminating the need for RejoinHostPort().

- Every time a string needs to be created on the heap AMB uses an explicit
  malloc() followed by strcpy(), sprintf() or related routines. I many places
  I've replaced this by strdup() or asprintf() (the latter is a GNU extension).
  This removes some irritating clutter in the code, improving readability and
  maintainability and reducing the risk of allocation-size errors.

- I fixed a problem in the function wwwoffles() which sometimes caused a server
  to exit without removing the temporary file it created.

- I created a separate header file for the declarations of the functions defined
  in src/header.c. Originally these declarations were contained in src/misc.h.

- I put some more code in to check the return values of read() or write()
  functions. This is to prevent further reading from or writing to a file
  descriptor once an error has been indicated.

- I fixed an allocation bug in src/ftp.c by making sure that the buffer that
  HTMLMessageBody() and htmlise_dir_entry() allocate is at least BUFSIZE+1 bytes
  large, which is what read_line_or_timeout() expects it to be.

- I my version headers from servers are not censored before being written to the
  cache, only before being sent to the browser. This ensures the headers in the
  cache more faithfully represent the original headers sent by the remote
  servers. Thus the way headers are censored is only determined by the
  configuration of WWWOFFLE at the time they are sent to browser, allowing you
  to change your mind without having to re-fetch any pages if you decide the
  censoring was too strict.

- I've introduced some optimizations that reduce the use of temporary files in
  some very common special cases, namely when serving the (unmodified) contents
  from a cached file or other local file. I've introduced code that copies the
  contents of the local file directly to the browser, instead of first copying
  it to a temporary file and then reading the temporary file back again.

- I've expanded the micro-language used in message templates to allow "if ...
  then ... elsif ... then ... else ... fi" -like constructs, e.g.
  $x?=a{...}$x?=b{...}$x?=c{...}{...}. Furthermore these conditional constructs
  can now be nested.

- I have debugged and enhanced the URL Configuration webpages. Very useful if
  you want to see how WWWOFFLE is configured for a particular URL. For instance
  if you want to see exactly which entry in the DontGet section causes a
  particular URL to be not got. I've also added a bookmarklet in
  contrib/bookmarklets/bookmarks.html that can be used to display the
  configuration for the current URL in a browser.

- I tried to make WWWOFFLE give more sensible error messages in some cases. For
  instance it was my experience that WWWOFFLE sometimes generated a message
  telling me that the connection to the remote server timed out before receiving
  a reply, even though there had been no noticeable delay. This of course made
  no sense to me. WWWOFFLE will now give a more sensible message in such a case
  (e.g. "Connection reset by peer").

- If the path part of a URL-specification begins with '/*' the internally used
  pattern object for the path will not contain the leading slash. Thus e.g.
  'http://foo.com/*/stuff/*' will use '*/stuff/*' for the path part and match
  both 'http://foo.com/stuff/' and 'http://foo.com/preamble/stuff/'. I find this
  more efficient, because in the past I had to use two entries with
  'http://foo.com/stuff/*' and 'http://foo.com/*/stuff/*' to get the same
  behavior. If you really don't want 'http://foo.com/stuff/' to match, it is
  always possible to list '!http://foo.com/stuff/*' before
  'http://foo.com/*/stuff/*'

- Path names of files that are to be included in the configuration file are
  treated as absolute when they begin with a '/'. In the the original version
  all such file names are treated as relative to the directory the main
  configuration file is in.

- I've introduced a function strcasestrn() that does a case-insensitive string
  search and is based on the glibc function strcasestr(), just as strstrn() is
  base on strstr(). This eliminates the need for temporarily allocating strings
  on the heap during a case-insensitive search and should thus allow for more
  efficient pattern matching.

In addition to the things I've listed above, I've made various little changes to
fix minor bugs, improve efficiency or elegance, or simply to suit my own coding
style. These changes are too numerous to list here, but you can always find out
about them by comparing the source of my modified version with AMB's original
code.

If you have any questions about the modifications I've made, you can send these
to <p.a.rombouts@home.nl>. Questions about the original WWWOFFLE version should
be sent to <wwwoffle-users@gedanken.demon.co.uk> or <amb@gedanken.demon.co.uk>.
